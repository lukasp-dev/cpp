### Thread-Safe Memory Allocators
#### Thread Level
여기서 말하는 스레드는 **user level thread(pthreads)** 이며, 여러 스레드가 동일한 프로세스 힙을 공유.

#### Why thread safety is needed
- malloc/free 는 공유 headp metadata를 수정
- 동시에 접근하면 free list 가 망가지거나 double-free같은 heap corruption이 발생
#### Basic solution
Allocator를 mutex로 감싸 직렬화 한다.
1. `lock`
2. 내부 allocator 호출
3. `unlock`

things like `pthread_mutex` are user-level API, but internally it is implemented utilizing the kernel-level futex/atomic operations. So let's dive in and get to know how the mutex internally works at the hardware/kernel level.

#### Proposed implementation of mutex
```
Lock():
    while(mem_lock != 0)
        block the thread
    mem_lock = 1;

Unlock():
    mem_lock = 0;
```
The main problem:
- `while(mem_lock != 0)` and `mem_lock = 1` are not atomic (쪼개질 수 있음). 
- example:
    **race condition**
    1. 스레드 A가 `mem_lock == 0` 을 확인하고 잠금 시도 직전 인터럽트 발생
    2. 스레드 B가 실행되어 `mem_lock = 1` 로 설정
    3. 다시 스레드 A가 돌아와 `mem_lock = 1`로 덮어씀

#### Hardware-level Mutex Implementation
- 문제: `mem_lock` 검사와 설정 is not atomic -> possible race condition
- 해결: Hardware provides atomic **Read-Modify-Write**

#### Test-and-Set
- 메모리 값 일고 동시에 1로 설정
- 원래 값이 0 -> 락(주도권) 획득
- 원래 값이 1 -> 이미 잠근 중, 재시도 필요
- 모든 동작이 atomic 하게 수행돼 인터럽트나 다른 CPU 개입 불가
    #### 유사 명령어    
    - `compare-and-swap` (IBM 370)
    - `fetch-and-add` (intel x86)
    - `load-linked/store-conditional` (MIPS, ARM)

#### new(safe) implementation of mutex
```
Lock():
    while(test_and_set(&mem_lock))
        block the thread

Unlock():
    mem_lock = 0
```
**Code Example**
```c
static int shared_lock = 1; /*global variable to both T1 and T2*/

/* shared procedure for T1 and T2 */
int binary-semaphore(int *L){
    int X;

    X = test_and_set(L);
    /*X = 0 for successful return*/
    return (X)
}
```
Two threads T1 and T2 execute the following statement simultaneously:
    `MyX = binary_semaphore(&shared_lock);`
where `MyX` is a local variable in each of T1 and T2.
- 두 스레드를 동시에 실행해도 가능한 결과: `(0, 1)` or `(1, 0)`.

Nowadays, the Symmetric Multi Processing (SMP) is prevalent(CPUs are sharing memory) -> the synchronization/mutex is crucial.
more specifically,

The System(hardware+OS) has to ensure
1. Threads of the same process share the same PT
2. Threads have synchronization atomicity
3. Threads have identical views of memory

### SMP 환경에서 TLB 관리
- TLB: "최근에 사용한 가상주소 -> 물리주소 변환을 캐싱해 둔 작은 메모리"
![image](https://i.postimg.cc/wT12JXZW/image-(7).png)

**1.background**
- 스레드/프로세스는 페이지 테이블을 공유->동일한 주소 공간 사룡
- TLB(Translation Lookaside Buffer)는 각 CPU 코어마다 따로 존재, 가상주소 -> 물리주소 변환 결과를 캐시
이 구조 떄문에 페이지 테이블이 변하면 TLB도 정리 해야됨.

**2.TLB during Context Switch**

상황
- CPU가 실행 중이던 프로세스 A -> 프로세스 B로 전환.

문제
- 해당 CPU 의 TLB 에는 ㅇ프로세스 A의 주소 변환 정보가 남아 있음.
- 프로세스 B와 주소 공간이 다르므로, 잘못된 주소로 접근할 위험

해결
- 스위치를 수행한 CPU 의 TLB만 flush
- 다른 CPU들은 자신이 실행 중이던 프로세스를 계속 수행하므로 TLB를 건드릴 필요가 없음.

**3.TLB during Page Replacement**

상황
- OS가 특정 가상 페이지의 매핑을 변경(invalidation, 다른 프레임으로 이동 등).
- 예: page X가 물리 프레임 F에서 제거되거나 다른 프레임으로 옮겨짐.

문제
- 여러 CPU가 과거에 page X를 접근했을 수 있다.
- 따라서 CPU0, CPU1, CPU...의 TLB에도 예날 매핑이 남아 있을 수 있음.
이를 제거하지 않으면 잘못된 물리주소로 접근하게 됨.

해결 = **TLB Shootdown**
1. OS가 페이지 테이블에서 page X 매핑 변경.
2. 다른 CPU들에 소프트웨어 인터럽트(TLB invalidate)를 전송.
3. 각 CPU는 TLB에서 Page X 엔트리만 invalidation 수행.
4. 모든 CPU가 처리 오나료 후 OS가 다음 단계 진행.

### Atomicity and Cache Coherence
1. why is caching a problem here?
- CPU has its own cache
- shared variables (i.e. lock vars) might be stored across different caches -> CPU might refer to the stale value
- therefore, the atomic operation(`test-and-set`, `compare-and-swap`) should rely on the most recent value, not the cached value

2. the real meanings of "cache bypass"(cache coherency)
- The CPU takes the cache line in an Exclusive/Modified state
    - This means only my CPU is allowed to read or write this variable
    - Other CPUs are not allowed to use that cache line anymore.
- Other CPUs' copies of that cache line are automatically Invalidated
    - The hardware forcibly invalidates the same cache line in other CPUs' caches.
    - The programmer or the OS **does not need to do anything.**
- The CPU performs the atomic operation in that exclusive state.
    - This guarantees the operation uses the **latest, correct value**(no stale data).
    - Atomicity and memory consistency are both protected.

3. How do other CPUs see the updated value?
- When another CPU tires to read that variable:
    1. It checks its cache and sees the lin eis invalid.
    2. it requests the latest value from memory (r from the CPU holding the Modified line).
    3. It loads the updated value into its own cache.

4. Details on how hardware implements cache coherency

![image](https://i.postimg.cc/DyjXQ0RD/image-(8).png)
- 기본 원리: 모든 CPU가 같은 메모리 값을 보게 하려면 캐시 간 동기화 필요
- 방법 1: **Write-invalidate**
    - 한 CPU가 메모리에 쓰면, 다른 CPU 캐시의 같은 주소 라인을 invalidate.
    - 다른 CPU가 다시 접근 시 메모리에서 최신 값 재로딩
- 방법 2: **Write-update**
    - 한 CPU가 값을 쓰면, 그 값을 다른 CPU캐시에도 즉시 반영.
    - 캐시 미스는 줄지만 트래픽이 많아져 잘 안 씀.
- 하트웨어 동작: 각 캐시는 버스를 snoop 하며 다른 CPU 의 쓰기 감지, 필요 시 invalidate 또는 update 수행.
**snoop: 각 CPU 캐시가 공유 버스의 메모리 트래픽을 감시해서 다른 CPU가 어떤 주소에 읽기나 쓰기를 하는지 실시간으로 확인하는 동작.